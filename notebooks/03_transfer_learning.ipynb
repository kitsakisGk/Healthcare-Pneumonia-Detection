{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Transfer Learning with ResNet50\n",
    "\n",
    "**Project:** AI-Powered Pneumonia Detection from Chest X-Rays  \n",
    "**Author:** Georgios Kitsakis  \n",
    "**Date:** 2025-10-29\n",
    "\n",
    "## Objectives\n",
    "1. Use pre-trained ResNet50 model\n",
    "2. Fine-tune for pneumonia detection\n",
    "3. Achieve 90-95% accuracy\n",
    "4. Generate detailed evaluation metrics\n",
    "5. Create confusion matrix and classification report\n",
    "\n",
    "## Why Transfer Learning?\n",
    "- **Pre-trained on ImageNet**: Already learned useful features\n",
    "- **Faster Training**: Only fine-tune last layers\n",
    "- **Better Accuracy**: State-of-the-art architecture\n",
    "- **Industry Standard**: Used in production systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup (Google Colab Compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab - GPU will be used!\")\n",
    "    \n",
    "    # Mount Google Drive (optional - to save models)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # You'll need to upload your dataset to Colab or Google Drive\n",
    "    # For now, we'll assume dataset is uploaded to /content/data/\n",
    "    BASE_DIR = '/content/data'\n",
    "    MODELS_DIR = '/content/drive/MyDrive/pneumonia_models'  # Save to Drive\n",
    "    REPORTS_DIR = '/content/drive/MyDrive/pneumonia_reports'\n",
    "    \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "    BASE_DIR = '../data'\n",
    "    MODELS_DIR = '../models'\n",
    "    REPORTS_DIR = '../reports'\n",
    "\n",
    "import os\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "VAL_DIR = os.path.join(BASE_DIR, 'val')\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 224  # ResNet50 expects 224x224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2 if torch.cuda.is_available() else 0  # Use workers on GPU\n",
    "NUM_EPOCHS = 10  # Fewer epochs needed with transfer learning\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms - ResNet expects 3-channel images and ImageNet normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['NORMAL', 'PNEUMONIA']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if not os.path.exists(class_path):\n",
    "                continue\n",
    "                \n",
    "            for img_name in os.listdir(class_path):\n",
    "                if img_name.endswith(('.jpeg', '.jpg', '.png')):\n",
    "                    self.images.append(os.path.join(class_path, img_name))\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Load as grayscale\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\nLoading datasets...\")\n",
    "train_dataset = ChestXRayDataset(TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = ChestXRayDataset(VAL_DIR, transform=val_test_transform)\n",
    "test_dataset = ChestXRayDataset(TEST_DIR, transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, pin_memory=True if torch.cuda.is_available() else False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=NUM_WORKERS, pin_memory=True if torch.cuda.is_available() else False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                         num_workers=NUM_WORKERS, pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_dataset)} images ({len(train_loader)} batches)\")\n",
    "print(f\"  Val: {len(val_dataset)} images ({len(val_loader)} batches)\")\n",
    "print(f\"  Test: {len(test_dataset)} images ({len(test_loader)} batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Transfer Learning Model\n",
    "\n",
    "We'll use **ResNet50** pre-trained on ImageNet and fine-tune it for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50\n",
    "print(\"Loading pre-trained ResNet50...\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Freeze early layers (we'll only train the last few layers)\n",
    "print(\"Freezing early layers...\")\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer4' not in name and 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Replace final fully connected layer for binary classification\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 2)  # 2 classes: NORMAL, PNEUMONIA\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel: ResNet50 (Transfer Learning)\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen Parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"\\nTraining only: layer4 and custom FC layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "print(\"Training Setup:\")\n",
    "print(f\"  Loss: Cross Entropy\")\n",
    "print(f\"  Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (factor=0.5, patience=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / len(dataloader.dataset), 100 * correct / total\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    return running_loss / len(dataloader.dataset), 100 * correct / total\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_path = os.path.join(MODELS_DIR, 'resnet50_best.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Starting Training - ResNet50 Transfer Learning\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss\n",
    "        }, best_model_path)\n",
    "        print(f\"  ✓ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Time: {elapsed_time/60:.2f} minutes\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs_range = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Loss\n",
    "ax1.plot(epochs_range, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o')\n",
    "ax1.plot(epochs_range, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss (ResNet50)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(epochs_range, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2, marker='o')\n",
    "ax2.plot(epochs_range, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2, marker='s')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Training and Validation Accuracy (ResNet50)', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORTS_DIR, 'training_curves_resnet50.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detailed Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']} (Val Acc: {checkpoint['val_acc']:.2f}%)\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "test_acc = accuracy_score(all_labels, all_predictions) * 100\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted') * 100\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted') * 100\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted') * 100\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Test Set Evaluation - ResNet50\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy:  {test_acc:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall:    {recall:.2f}%\")\n",
    "print(f\"F1-Score:  {f1:.2f}%\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "class_names = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'}, linewidths=1, linecolor='black')\n",
    "plt.title('Confusion Matrix - ResNet50', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Add percentages\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        percentage = cm[i, j] / cm[i].sum() * 100\n",
    "        plt.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)', \n",
    "                ha='center', va='center', fontsize=11, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORTS_DIR, 'confusion_matrix_resnet50.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate Sensitivity & Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "sensitivity = tp / (tp + fn) * 100  # True Positive Rate (Recall for PNEUMONIA)\n",
    "specificity = tn / (tn + fp) * 100  # True Negative Rate\n",
    "ppv = tp / (tp + fp) * 100  # Positive Predictive Value (Precision for PNEUMONIA)\n",
    "npv = tn / (tn + fn) * 100  # Negative Predictive Value\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Medical Metrics (PNEUMONIA Detection)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Sensitivity (Recall):           {sensitivity:.2f}%  [TP / (TP + FN)]\")\n",
    "print(f\"Specificity:                    {specificity:.2f}%  [TN / (TN + FP)]\")\n",
    "print(f\"Positive Predictive Value:      {ppv:.2f}%  [TP / (TP + FP)]\")\n",
    "print(f\"Negative Predictive Value:      {npv:.2f}%  [TN / (TN + FN)]\")\n",
    "print(f\"\\nConfusion Matrix Values:\")\n",
    "print(f\"  True Positives (TP):  {tp}\")\n",
    "print(f\"  True Negatives (TN):  {tn}\")\n",
    "print(f\"  False Positives (FP): {fp}\")\n",
    "print(f\"  False Negatives (FN): {fn}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_summary = f\"\"\"\n",
    "# ResNet50 Transfer Learning Results\n",
    "\n",
    "**Author:** Georgios Kitsakis  \n",
    "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Model:** ResNet50 (Transfer Learning)\n",
    "\n",
    "## Training Configuration\n",
    "- Image Size: {IMG_SIZE}x{IMG_SIZE}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Epochs: {NUM_EPOCHS}\n",
    "- Learning Rate: {LEARNING_RATE}\n",
    "- Device: {device}\n",
    "- Training Time: {elapsed_time/60:.2f} minutes\n",
    "\n",
    "## Model Architecture\n",
    "- Base: ResNet50 (pre-trained on ImageNet)\n",
    "- Trainable Parameters: {trainable_params:,}\n",
    "- Total Parameters: {total_params:,}\n",
    "\n",
    "## Results\n",
    "\n",
    "### Overall Metrics\n",
    "- **Test Accuracy:** {test_acc:.2f}%\n",
    "- **Precision:** {precision:.2f}%\n",
    "- **Recall:** {recall:.2f}%\n",
    "- **F1-Score:** {f1:.2f}%\n",
    "\n",
    "### Medical Metrics\n",
    "- **Sensitivity (TPR):** {sensitivity:.2f}%\n",
    "- **Specificity (TNR):** {specificity:.2f}%\n",
    "- **Positive Predictive Value:** {ppv:.2f}%\n",
    "- **Negative Predictive Value:** {npv:.2f}%\n",
    "\n",
    "### Confusion Matrix\n",
    "```\n",
    "                Predicted\n",
    "              NORMAL  PNEUMONIA\n",
    "Actual NORMAL    {tn}      {fp}\n",
    "       PNEUMONIA {fn}      {tp}\n",
    "```\n",
    "\n",
    "## Key Findings\n",
    "- Transfer learning significantly improved accuracy compared to baseline CNN\n",
    "- Model shows strong performance in detecting pneumonia cases\n",
    "- High sensitivity is crucial for medical applications (minimize false negatives)\n",
    "\n",
    "## Next Steps\n",
    "- Implement Grad-CAM for explainability\n",
    "- Deploy in Streamlit web application\n",
    "- Consider ensemble methods for further improvement\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "results_path = os.path.join(REPORTS_DIR, 'results_resnet50.md')\n",
    "with open(results_path, 'w') as f:\n",
    "    f.write(results_summary)\n",
    "\n",
    "print(f\"\\nResults summary saved to: {results_path}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 3 COMPLETE: Transfer Learning with ResNet50\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
