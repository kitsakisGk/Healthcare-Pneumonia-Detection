{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 2: Model Training with Transfer Learning\n\n**Project:** AI-Powered Pneumonia Detection from Chest X-Rays  \n**Author:** Georgios Kitsakis  \n**Date:** 2025-10-29\n\n## Objectives\n1. Use pre-trained ResNet50 (transfer learning)\n2. Fine-tune for pneumonia detection\n3. Track metrics (loss, accuracy, precision, recall)\n4. Save best model checkpoint\n5. Generate confusion matrix and evaluation metrics\n6. Achieve 90-95% accuracy"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint(f\"PyTorch Version: {torch.__version__}\")\n\n# Configure matplotlib\nplt.style.use('seaborn-v0_8-darkgrid')\n%matplotlib inline"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recreate Dataset and DataLoaders\n",
    "\n",
    "We'll reuse the code from Phase 1 to load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset paths\nBASE_DIR = os.path.join('..', 'data')\nTRAIN_DIR = os.path.join(BASE_DIR, 'train')\nTEST_DIR = os.path.join(BASE_DIR, 'test')\nVAL_DIR = os.path.join(BASE_DIR, 'val')\n\n# Hyperparameters\nIMG_SIZE = 224\nBATCH_SIZE = 32\nNUM_WORKERS = 0  # Set to 0 for Windows compatibility\nNUM_EPOCHS = 10  # Fewer epochs with transfer learning\nLEARNING_RATE = 0.0001\n\nprint(f\"Training Configuration:\")\nprint(f\"  Image Size: {IMG_SIZE}x{IMG_SIZE}\")\nprint(f\"  Batch Size: {BATCH_SIZE}\")\nprint(f\"  Epochs: {NUM_EPOCHS}\")\nprint(f\"  Learning Rate: {LEARNING_RATE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Transforms - ResNet expects 3 channels and ImageNet normalization\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels for ResNet\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n])\n\nval_test_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Custom Dataset\nclass ChestXRayDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['NORMAL', 'PNEUMONIA']\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        \n        self.images = []\n        self.labels = []\n        \n        for class_name in self.classes:\n            class_path = os.path.join(root_dir, class_name)\n            if not os.path.exists(class_path):\n                continue\n                \n            for img_name in os.listdir(class_path):\n                if img_name.endswith(('.jpeg', '.jpg', '.png')):\n                    self.images.append(os.path.join(class_path, img_name))\n                    self.labels.append(self.class_to_idx[class_name])\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert('L')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n# Create datasets\nprint(\"\\nLoading datasets...\")\ntrain_dataset = ChestXRayDataset(TRAIN_DIR, transform=train_transform)\nval_dataset = ChestXRayDataset(VAL_DIR, transform=val_test_transform)\ntest_dataset = ChestXRayDataset(TEST_DIR, transform=val_test_transform)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\nprint(f\"\\nDataset sizes:\")\nprint(f\"  Train: {len(train_dataset)} images ({len(train_loader)} batches)\")\nprint(f\"  Val: {len(val_dataset)} images ({len(val_loader)} batches)\")\nprint(f\"  Test: {len(test_dataset)} images ({len(test_loader)} batches)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Load Pre-trained ResNet50\n\nTransfer learning: Use ResNet50 trained on ImageNet, freeze early layers, fine-tune last layers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load pre-trained ResNet50\nprint(\"Loading pre-trained ResNet50...\")\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n\n# Freeze early layers\nprint(\"Freezing early layers...\")\nfor name, param in model.named_parameters():\n    if 'layer4' not in name and 'fc' not in name:\n        param.requires_grad = False\n\n# Replace final layer for binary classification\nnum_features = model.fc.in_features\nmodel.fc = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(num_features, 256),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(256, 2)  # 2 classes\n)\n\nmodel = model.to(device)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\nModel: ResNet50 (Transfer Learning)\")\nprint(f\"Total Parameters: {total_params:,}\")\nprint(f\"Trainable Parameters: {trainable_params:,}\")\nprint(f\"Frozen Parameters: {total_params - trainable_params:,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Training Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\nprint(\"Training Setup:\")\nprint(f\"  Loss: Cross Entropy\")\nprint(f\"  Optimizer: Adam (lr={LEARNING_RATE})\")\nprint(f\"  Scheduler: ReduceLROnPlateau\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Training Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate for one epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Training and validation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Train the Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training history\nhistory = {\n    'train_loss': [],\n    'train_acc': [],\n    'val_loss': [],\n    'val_acc': []\n}\n\nbest_val_acc = 0.0\nbest_model_path = '../models/resnet50_pneumonia.pth'\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Starting Training - ResNet50 Transfer Learning\")\nprint(\"=\"*60)\n\nstart_time = time.time()\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch [{epoch+1}/{NUM_EPOCHS}]\")\n    \n    # Train\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    \n    # Validate\n    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n    \n    # Update scheduler\n    scheduler.step(val_loss)\n    \n    # Save history\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    \n    # Print results\n    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n    \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_acc': val_acc,\n            'val_loss': val_loss\n        }, best_model_path)\n        print(f\"  ✓ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n\nelapsed_time = time.time() - start_time\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Training Complete!\")\nprint(\"=\"*60)\nprint(f\"Total Time: {elapsed_time/60:.2f} minutes\")\nprint(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Visualize Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\nepochs_range = range(1, NUM_EPOCHS + 1)\n\n# Loss\nax1.plot(epochs_range, history['train_loss'], 'b-', label='Training Loss', linewidth=2, marker='o')\nax1.plot(epochs_range, history['val_loss'], 'r-', label='Validation Loss', linewidth=2, marker='s')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('Loss', fontsize=12)\nax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# Accuracy\nax2.plot(epochs_range, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2, marker='o')\nax2.plot(epochs_range, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2, marker='s')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('Accuracy (%)', fontsize=12)\nax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('../reports/training_curves.png', dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Test Evaluation with Confusion Matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load best model\ncheckpoint = torch.load(best_model_path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nprint(f\"Loaded best model from epoch {checkpoint['epoch']} (Val Acc: {checkpoint['val_acc']:.2f}%)\")\n\n# Evaluate on test set\nmodel.eval()\nall_predictions = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc='Testing'):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        \n        all_predictions.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate metrics\ntest_acc = accuracy_score(all_labels, all_predictions) * 100\n\n# Confusion matrix\ncm = confusion_matrix(all_labels, all_predictions)\nclass_names = ['NORMAL', 'PNEUMONIA']\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names,\n            cbar_kws={'label': 'Count'}, linewidths=1, linecolor='black')\nplt.title('Confusion Matrix - ResNet50', fontsize=16, fontweight='bold', pad=20)\nplt.xlabel('Predicted Label', fontsize=13, fontweight='bold')\nplt.ylabel('True Label', fontsize=13, fontweight='bold')\n\n# Add percentages\nfor i in range(len(class_names)):\n    for j in range(len(class_names)):\n        percentage = cm[i, j] / cm[i].sum() * 100\n        plt.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)', \n                ha='center', va='center', fontsize=11, color='red')\n\nplt.tight_layout()\nplt.savefig('../reports/confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n# Print classification report\nprint(f\"\\n{'='*60}\")\nprint(f\"Test Set Evaluation\")\nprint(f\"{'='*60}\")\nprint(f\"Test Accuracy: {test_acc:.2f}%\")\nprint(f\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_predictions, target_names=class_names, digits=4))\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"PHASE 2 COMPLETE: Transfer Learning with ResNet50\")\nprint(\"=\"*60)\nprint(\"\\n✓ ResNet50 model fine-tuned\")\nprint(\"✓ Model trained for\", NUM_EPOCHS, \"epochs\")\nprint(\"✓ Best model saved\")\nprint(\"✓ Training curves visualized\")\nprint(\"✓ Confusion matrix generated\")\nprint(\"✓ Test evaluation complete\")\nprint(\"\\nResults:\")\nprint(f\"  Best Validation Accuracy: {best_val_acc:.2f}%\")\nprint(f\"  Test Accuracy: {test_acc:.2f}%\")\nprint(f\"  Trainable Parameters: {trainable_params:,}\")\nprint(f\"  Training Time: {elapsed_time/60:.2f} minutes\")\nprint(\"\\nNext Phase: Grad-CAM for Explainability\")\nprint(\"=\"*60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}