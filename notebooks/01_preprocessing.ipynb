{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Exploration & Preprocessing\n",
    "\n",
    "**Project:** AI-Powered Pneumonia Detection from Chest X-Rays  \n",
    "**Author:** Georgios Kitsakis  \n",
    "**Date:** 2025-10-27\n",
    "\n",
    "## Objectives\n",
    "1. Load and explore the Chest X-Ray dataset\n",
    "2. Visualize sample images from both classes (Normal vs Pneumonia)\n",
    "3. Analyze class distribution and data balance\n",
    "4. Implement preprocessing pipeline (resize, normalize)\n",
    "5. Apply data augmentation techniques\n",
    "6. Create PyTorch DataLoaders for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "The dataset should be organized as:\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── NORMAL/\n",
    "│   └── PNEUMONIA/\n",
    "├── test/\n",
    "│   ├── NORMAL/\n",
    "│   └── PNEUMONIA/\n",
    "└── val/\n",
    "    ├── NORMAL/\n",
    "    └── PNEUMONIA/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "BASE_DIR = os.path.join('..', 'data')\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'test')\n",
    "VAL_DIR = os.path.join(BASE_DIR, 'val')\n",
    "\n",
    "# Check if data directories exist\n",
    "for dir_path in [TRAIN_DIR, TEST_DIR, VAL_DIR]:\n",
    "    if os.path.exists(dir_path):\n",
    "        print(f\"✓ {dir_path} exists\")\n",
    "    else:\n",
    "        print(f\"✗ {dir_path} NOT FOUND - Please download and extract the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(directory):\n",
    "    \"\"\"Count images in each class folder\"\"\"\n",
    "    counts = {}\n",
    "    for class_name in ['NORMAL', 'PNEUMONIA']:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            counts[class_name] = len([f for f in os.listdir(class_path) \n",
    "                                      if f.endswith(('.jpeg', '.jpg', '.png'))])\n",
    "        else:\n",
    "            counts[class_name] = 0\n",
    "    return counts\n",
    "\n",
    "# Count images in each split\n",
    "train_counts = count_images(TRAIN_DIR)\n",
    "test_counts = count_images(TEST_DIR)\n",
    "val_counts = count_images(VAL_DIR)\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Test': test_counts,\n",
    "    'Validation': val_counts\n",
    "})\n",
    "\n",
    "summary_df.loc['Total'] = summary_df.sum()\n",
    "\n",
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(summary_df)\n",
    "print(f\"\\nTotal Images: {summary_df.loc['Total'].sum():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "splits = ['Train', 'Test', 'Validation']\n",
    "data = [train_counts, test_counts, val_counts]\n",
    "\n",
    "for ax, split, counts in zip(axes, splits, data):\n",
    "    classes = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "    colors = ['#2ecc71', '#e74c3c']  # Green for Normal, Red for Pneumonia\n",
    "    \n",
    "    ax.bar(classes, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{split} Set Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_xlabel('Class')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(values):\n",
    "        ax.text(i, v + max(values)*0.02, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "pneumonia_ratio = train_counts['PNEUMONIA'] / (train_counts['NORMAL'] + train_counts['PNEUMONIA'])\n",
    "print(f\"\\nClass Imbalance in Training Set:\")\n",
    "print(f\"  NORMAL: {(1-pneumonia_ratio)*100:.1f}%\")\n",
    "print(f\"  PNEUMONIA: {pneumonia_ratio*100:.1f}%\")\n",
    "print(f\"  Imbalance Ratio: {train_counts['PNEUMONIA']/train_counts['NORMAL']:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(directory, num_samples=3):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))\n",
    "    \n",
    "    for idx, class_name in enumerate(['NORMAL', 'PNEUMONIA']):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpeg', '.jpg', '.png'))][:num_samples]\n",
    "        \n",
    "        for i, img_file in enumerate(image_files):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "            \n",
    "            axes[idx, i].imshow(img, cmap='gray')\n",
    "            axes[idx, i].axis('off')\n",
    "            axes[idx, i].set_title(f'{class_name}\\n{img.size[0]}x{img.size[1]}', \n",
    "                                  fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/sample_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Sample X-Ray Images:\")\n",
    "display_sample_images(TRAIN_DIR, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(directory, sample_size=100):\n",
    "    \"\"\"Analyze dimensions and properties of images\"\"\"\n",
    "    widths, heights = [], []\n",
    "    \n",
    "    for class_name in ['NORMAL', 'PNEUMONIA']:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpeg', '.jpg', '.png'))][:sample_size]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            widths.append(img.size[0])\n",
    "            heights.append(img.size[1])\n",
    "    \n",
    "    print(f\"\\nImage Dimensions Analysis (sample of {len(widths)} images):\")\n",
    "    print(f\"  Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.0f}\")\n",
    "    print(f\"  Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.0f}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist(widths, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Image Width Distribution')\n",
    "    axes[0].set_xlabel('Width (pixels)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    axes[1].hist(heights, bins=30, color='salmon', edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_title('Image Height Distribution')\n",
    "    axes[1].set_xlabel('Height (pixels)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/image_dimensions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "analyze_image_properties(TRAIN_DIR, sample_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Preprocessing Transforms\n",
    "\n",
    "We'll create two sets of transforms:\n",
    "- **Training**: Include augmentation (rotation, flip, contrast)\n",
    "- **Validation/Test**: Only resize and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size for model input\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "print(\"Transforms defined:\")\n",
    "print(f\"  Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  Training augmentation: Random flip, rotation, color jitter\")\n",
    "print(f\"  Normalization: mean=0.5, std=0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Augmentation Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentation_examples(image_path, transform, num_examples=5):\n",
    "    \"\"\"Show multiple augmented versions of the same image\"\"\"\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_examples + 1, figsize=(18, 3))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title('Original', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Augmented versions\n",
    "    for i in range(1, num_examples + 1):\n",
    "        augmented = transform(img)\n",
    "        # Denormalize for visualization\n",
    "        augmented = augmented * 0.5 + 0.5\n",
    "        axes[i].imshow(augmented.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Augmented {i}', fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/augmentation_examples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Get a sample image\n",
    "sample_img_path = os.path.join(TRAIN_DIR, 'PNEUMONIA', \n",
    "                               os.listdir(os.path.join(TRAIN_DIR, 'PNEUMONIA'))[0])\n",
    "\n",
    "print(\"Data Augmentation Examples:\")\n",
    "show_augmentation_examples(sample_img_path, train_transform, num_examples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for Chest X-Ray images\n",
    "    \n",
    "    Args:\n",
    "        root_dir: Path to train/test/val directory\n",
    "        transform: Torchvision transforms to apply\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['NORMAL', 'PNEUMONIA']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Load all image paths and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if not os.path.exists(class_path):\n",
    "                continue\n",
    "                \n",
    "            for img_name in os.listdir(class_path):\n",
    "                if img_name.endswith(('.jpeg', '.jpg', '.png')):\n",
    "                    self.images.append(os.path.join(class_path, img_name))\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} images from {root_dir}\")\n",
    "        print(f\"  NORMAL: {self.labels.count(0)}\")\n",
    "        print(f\"  PNEUMONIA: {self.labels.count(1)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image and convert to grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4  # Adjust based on your CPU\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating datasets...\\n\")\n",
    "train_dataset = ChestXRayDataset(TRAIN_DIR, transform=train_transform)\n",
    "print()\n",
    "val_dataset = ChestXRayDataset(VAL_DIR, transform=val_test_transform)\n",
    "print()\n",
    "test_dataset = ChestXRayDataset(TEST_DIR, transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dataloader by fetching one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch shape: {images.shape}\")  # Should be [batch_size, 1, 224, 224]\n",
    "print(f\"Labels shape: {labels.shape}\")  # Should be [batch_size]\n",
    "print(f\"Image dtype: {images.dtype}\")\n",
    "print(f\"Labels: {labels[:10]}\")\n",
    "print(f\"Image range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "\n",
    "# Visualize a batch\n",
    "def show_batch(images, labels, num_images=8):\n",
    "    \"\"\"Display a batch of images with labels\"\"\"\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names = ['NORMAL', 'PNEUMONIA']\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Denormalize image\n",
    "        img = images[i] * 0.5 + 0.5\n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'{class_names[labels[i]]}', fontweight='bold', \n",
    "                         color='green' if labels[i] == 0 else 'red')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample batch from training set:\")\n",
    "show_batch(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASE 1 COMPLETE: Data Exploration & Preprocessing\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✓ Dataset loaded and explored\")\n",
    "print(\"✓ Class distribution analyzed\")\n",
    "print(\"✓ Image properties examined\")\n",
    "print(\"✓ Preprocessing pipeline created\")\n",
    "print(\"✓ Data augmentation implemented\")\n",
    "print(\"✓ PyTorch DataLoaders ready\")\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"  - Total images: {len(train_dataset) + len(val_dataset) + len(test_dataset)}\")\n",
    "print(f\"  - Training images: {len(train_dataset)}\")\n",
    "print(f\"  - Validation images: {len(val_dataset)}\")\n",
    "print(f\"  - Test images: {len(test_dataset)}\")\n",
    "print(f\"  - Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(\"\\nNext Phase: Model Building & Training\")\n",
    "print(\"  → Create 02_training.ipynb\")\n",
    "print(\"  → Build baseline CNN\")\n",
    "print(\"  → Train and evaluate\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
